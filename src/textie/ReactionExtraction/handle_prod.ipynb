{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 格式转换： 将prod的bio数据转换为json格式的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "\n",
    "base_dir=os.getcwd()\n",
    "\n",
    "def write_dict_to_file(data,file_path):\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False,indent=4)\n",
    "    \n",
    "\n",
    "def read_json_file(data_dir):\n",
    "    with open(data_dir,'r',encoding='utf-8') as file:\n",
    "            data=json.load(file)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r'''\n",
    "    功能：将实体识别的BIO的数据格式转换为我们需要的数据格式\n",
    "    数据的格式示例：\n",
    "        [\n",
    "            {\n",
    "                \"text\":,\n",
    "                'metainfo':,\n",
    "                'products':[,]\n",
    "            },\n",
    "        ]\n",
    "'''\n",
    "def data_transfer(input_file,out_file=None):\n",
    "    pass\n",
    "    data_list=[]\n",
    "    \n",
    "    with open(input_file, encoding=\"utf-8\") as f:\n",
    "        words, labels = [], []\n",
    "        metainfo = None\n",
    "        for line in f:\n",
    "            line = line.rstrip()#去除右侧空白字符\n",
    "            if line.startswith(\"#\\tpassage\"):\n",
    "                metainfo = line\n",
    "            elif line == \"\":\n",
    "                if words:\n",
    "                        data_item={}\n",
    "                        text=''\n",
    "                        for i,word in enumerate(words):\n",
    "                             text+=word\n",
    "                             if i !=len(words)-1:\n",
    "                                text+=' '\n",
    "                        data_item['text']=text\n",
    "                        data_item['metainfo']=metainfo\n",
    "                        \n",
    "                        data_item['products']=products=[]\n",
    "                        \n",
    "                        entities = get_entities(labels)\n",
    "                        #[('Prod', 9, 9), ('Reactants', 17, 17), ('Reactants', 21, 21), ('Solvent', 25, 25), ('Temperature', 27, 29)]\n",
    "                        #print(entities)\n",
    "                        \n",
    "                        for entity in entities:\n",
    "                            entity_label=entity[0]\n",
    "                            \n",
    "                            if entity_label=='Prod':\n",
    "                                    entity_label='Product'\n",
    "                            entity_beg=entity[1]\n",
    "                            entity_end=entity[2]\n",
    "                            entity_words=\"\"\n",
    "                            for i in range(entity_beg,entity_end+1):\n",
    "                                entity_words+=words[i]\n",
    "                                if i !=entity_end:\n",
    "                                    entity_words+=' '\n",
    "                            products.append(entity_words)\n",
    "                            \n",
    "                        data_list.append(data_item)\n",
    "                        words, labels = [], []\n",
    "                        \n",
    "                       \n",
    "            else:\n",
    "                cols = line.split(\"\\t\")\n",
    "                words.append(cols[0]) \n",
    "                labels.append(cols[1])\n",
    "                \n",
    "    #print(data_list)\n",
    "    write_dict_to_file(data_list,out_file)\n",
    "    return data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir='/data/lizh/ChemRxnExtractor-main/llm_role/data/prod'\n",
    "\n",
    "for file_item in os.listdir(base_dir):\n",
    "    file_name=os.path.join(base_dir,file_item)\n",
    "    if \"test\" in file_name:\n",
    "        data_transfer(file_name,base_dir+\"/test.json\")\n",
    "    elif \"train\" in file_name:\n",
    "        data_transfer(file_name,base_dir+\"/train.json\")\n",
    "    else:\n",
    "        data_transfer(file_name,base_dir+'/dev.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemrxn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
